{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd0497fcd8131e0146a97329183202dc5b52e74356af60b10336fb4fcc3db0452ec",
   "display_name": "Python 3.7.4 64-bit ('miniconda3': virtualenv)",
   "language": "python"
  },
  "metadata": {
   "interpreter": {
    "hash": "c5e72e1853e3e82b0c26ee06677180d9d6dc5e90f81bb00734beec12adee3b52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Make tensors (time, location, age; count)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gzip\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOTPATH = \"../dat/raw/\"\n",
    "OUTPATH = \"../out/processed/\"\n",
    "os.makedirs(OUTPATH, exist_ok=True)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(date_index):\n",
    "    return pd.read_csv(ROOTPATH + date_index + \"-citibike-tripdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_station_data(start=\"2017-01\", end=\"2020-12\", outpath=None):\n",
    "    \"\"\" Extract the consisten station information\n",
    "        between 'start' and 'end'.\n",
    "    \"\"\"\n",
    "\n",
    "    df_station_list = []\n",
    "\n",
    "    for date_index in tqdm.tqdm(pd.date_range(start=\"2016-01\", end=\"2020-12\", freq='m')):\n",
    "\n",
    "        # original trip data\n",
    "        df = load_data(date_index.strftime(\"%Y%m\"))\n",
    "\n",
    "        # ensure the consistency of column names\n",
    "        df.columns = df.columns.str.replace(\" \", \"\")\n",
    "        df.columns = df.columns.str.lower()\n",
    "\n",
    "        # start station data\n",
    "        df_stt = df[[\n",
    "            \"startstationid\",\n",
    "            \"startstationname\",\n",
    "            \"startstationlatitude\",\n",
    "            \"startstationlongitude\"\n",
    "        ]]\n",
    "\n",
    "        # end station data\n",
    "        df_end = df[[\n",
    "            \"endstationid\",\n",
    "            \"endstationname\",\n",
    "            \"endstationlatitude\",\n",
    "            \"endstationlongitude\"\n",
    "        ]]\n",
    "\n",
    "        # rename columns\n",
    "        df_stt.columns = df_stt.columns.str.replace(\"start\", \"\")\n",
    "        df_end.columns = df_end.columns.str.replace(\"end\", \"\")\n",
    "\n",
    "        # get unique station data\n",
    "        df = pd.concat([df_stt, df_end])\n",
    "        df = df.drop_duplicates(subset=[\"stationid\"])\n",
    "\n",
    "        df_station_list.append(df.copy())\n",
    "\n",
    "    # extract full station data\n",
    "    station_data = pd.concat(df_station_list)\n",
    "    station_data = station_data.drop_duplicates(subset=[\"stationid\"])\n",
    "    station_data = station_data.dropna(how=\"any\")\n",
    "    station_data = station_data.sort_values(\"stationname\")\n",
    "    station_data = station_data.reset_index(drop=True)  # remove unused index\n",
    "    station_data = station_data.reset_index(drop=True)  # remove unused index\n",
    "    station_data = station_data.reset_index()  # save unique id from zero\n",
    "    station_data = station_data.astype({\"stationid\": int})\n",
    "\n",
    "    if outpath is not None:\n",
    "        station_data.to_csv(\n",
    "            os.path.join(outpath, \"station_data.csv\"),\n",
    "            index=False)\n",
    "\n",
    "    return station_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df, year):\n",
    "    \"\"\" Load $ preprocess the original trip data \"\"\"\n",
    "\n",
    "    # Cleaning\n",
    "    df = df.dropna(how=\"any\")\n",
    "    df.columns = df.columns.str.replace(\" \", \"\")\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df = df.query(\"usertype=='Subscriber'\")\n",
    "\n",
    "    # Calculate user ages\n",
    "    df[\"userage\"] = year - df[\"birthyear\"]\n",
    "    df = df.query(\"userage<80\")\n",
    "    df = df.query(\"userage>10\")\n",
    "\n",
    "    # Extract columns that we want to use\n",
    "    df = df[[\"starttime\", \"startstationid\", \"endstationid\", \"userage\"]]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # Cast\n",
    "    return df.astype({\n",
    "        \"startstationid\": int,\n",
    "        \"endstationid\": int,\n",
    "        \"userage\": int\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f1ce1d7c3f27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"201506\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2015\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muserage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# sample\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "process(load_data(\"201506\"), 2015).userage.hist(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(start=\"2017-01\", end=\"2020-12\"):\n",
    "\n",
    "    dataset_path = OUTPATH + \"citibike_{}_{}/\".format(\n",
    "        start.replace(\"-\", \"\"), end.replace(\"-\", \"\"))\n",
    "    if os.path.exists(dataset_path):\n",
    "        shutil.rmtree(dataset_path)\n",
    "    os.makedirs(dataset_path)\n",
    "\n",
    "    # Get Station Information\n",
    "    station_data = generate_station_data(start, end, dataset_path)\n",
    "\n",
    "    # Make Monthly Trip History\n",
    "    for date_index in pd.date_range(start=start, end=end, freq='m'):\n",
    "\n",
    "        # data loading and cleaning\n",
    "        df = load_data(date_index.strftime(\"%Y%m\"))\n",
    "        df = process(df, date_index.year)\n",
    "\n",
    "        # encode start station indices\n",
    "        df = pd.merge(df, station_data[[\"index\", \"stationid\"]],\n",
    "                      how=\"left\",\n",
    "                      left_on=\"startstationid\",\n",
    "                      right_on=\"stationid\")\n",
    "\n",
    "        df = df.rename({\"index\": \"start_station_dim\"}, axis=1)\n",
    "        del df[\"stationid\"]\n",
    "\n",
    "        # encode end station indices\n",
    "        df = pd.merge(df, station_data[[\"index\", \"stationid\"]],\n",
    "                      how=\"left\",\n",
    "                      left_on=\"endstationid\",\n",
    "                      right_on=\"stationid\")\n",
    "\n",
    "        df = df.rename({\"index\": \"end_station_dim\"}, axis=1)\n",
    "        del df[\"stationid\"]\n",
    "\n",
    "        # final cleaning\n",
    "        df = df.dropna(how=\"any\")\n",
    "\n",
    "        # save as csv\n",
    "        filename = \"tripdata_{}.csv\".format(date_index.strftime(\"%Y%m\"))\n",
    "        df.to_csv(dataset_path + filename, index=False)\n",
    "        # compression\n",
    "        with open(dataset_path + filename, 'rb') as f_in:\n",
    "            with gzip.open(dataset_path + filename + \".gz\", \"wb\") as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "        print(\"[SAVED]\", filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 59/59 [02:40<00:00,  2.72s/it]\n",
      "[SAVED] tripdata_201703.csv\n",
      "[SAVED] tripdata_201704.csv\n",
      "[SAVED] tripdata_201705.csv\n",
      "[SAVED] tripdata_201706.csv\n",
      "[SAVED] tripdata_201707.csv\n",
      "[SAVED] tripdata_201708.csv\n",
      "[SAVED] tripdata_201709.csv\n",
      "[SAVED] tripdata_201710.csv\n",
      "[SAVED] tripdata_201711.csv\n",
      "[SAVED] tripdata_201712.csv\n",
      "[SAVED] tripdata_201801.csv\n",
      "[SAVED] tripdata_201802.csv\n",
      "[SAVED] tripdata_201803.csv\n",
      "[SAVED] tripdata_201804.csv\n",
      "[SAVED] tripdata_201805.csv\n",
      "[SAVED] tripdata_201806.csv\n",
      "[SAVED] tripdata_201807.csv\n",
      "[SAVED] tripdata_201808.csv\n",
      "[SAVED] tripdata_201809.csv\n",
      "[SAVED] tripdata_201810.csv\n",
      "[SAVED] tripdata_201811.csv\n",
      "[SAVED] tripdata_201812.csv\n",
      "[SAVED] tripdata_201901.csv\n",
      "[SAVED] tripdata_201902.csv\n",
      "[SAVED] tripdata_201903.csv\n",
      "[SAVED] tripdata_201904.csv\n",
      "[SAVED] tripdata_201905.csv\n",
      "[SAVED] tripdata_201906.csv\n",
      "[SAVED] tripdata_201907.csv\n",
      "[SAVED] tripdata_201908.csv\n",
      "[SAVED] tripdata_201909.csv\n",
      "[SAVED] tripdata_201910.csv\n",
      "[SAVED] tripdata_201911.csv\n",
      "[SAVED] tripdata_201912.csv\n",
      "[SAVED] tripdata_202001.csv\n",
      "[SAVED] tripdata_202002.csv\n",
      "[SAVED] tripdata_202003.csv\n",
      "[SAVED] tripdata_202004.csv\n",
      "[SAVED] tripdata_202005.csv\n",
      "[SAVED] tripdata_202006.csv\n",
      "[SAVED] tripdata_202007.csv\n",
      "[SAVED] tripdata_202008.csv\n",
      "[SAVED] tripdata_202009.csv\n",
      "[SAVED] tripdata_202010.csv\n",
      "[SAVED] tripdata_202011.csv\n",
      "[SAVED] tripdata_202012.csv\n",
      "[SAVED] tripdata_202101.csv\n",
      "[SAVED] tripdata_202102.csv\n",
      "[SAVED] tripdata_202103.csv\n"
     ]
    }
   ],
   "source": [
    "save_dataset(start=\"2017-03\", end=\"2021-04\")\n",
    "# save_dataset(start=\"2019-03\", end=\"2021-04\")  # 2021-04 will be excluded\n",
    "# save_dataset(start=\"2017-01\", end=\"2021-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}