{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd0497fcd8131e0146a97329183202dc5b52e74356af60b10336fb4fcc3db0452ec",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "c5e72e1853e3e82b0c26ee06677180d9d6dc5e90f81bb00734beec12adee3b52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Make tensors (time, location, age; count)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOTPATH = \"../dat/raw/\"\n",
    "OUTPATH = \"../dat/\"\n",
    "os.makedirs(OUTPATH, exist_ok=True)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(date_index):\n",
    "    return pd.read_csv(ROOTPATH + date_index + \"-citibike-tripdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_station_data(start=\"2017-01\", end=\"2020-12\", outpath=None):\n",
    "    \"\"\" Extract the consisten station information\n",
    "        between 'start' and 'end'.\n",
    "    \"\"\"\n",
    "\n",
    "    df_station_list = []\n",
    "\n",
    "    for date_index in tqdm.tqdm(pd.date_range(start=\"2016-01\", end=\"2020-12\", freq='m')):\n",
    "\n",
    "        # original trip data\n",
    "        df = load_data(date_index.strftime(\"%Y%m\"))\n",
    "\n",
    "        # ensure the consistency of column names\n",
    "        df.columns = df.columns.str.replace(\" \", \"\")\n",
    "        df.columns = df.columns.str.lower()\n",
    "\n",
    "        # start station data\n",
    "        df_stt = df[[\n",
    "            \"startstationid\",\n",
    "            \"startstationname\",\n",
    "            \"startstationlatitude\",\n",
    "            \"startstationlongitude\"\n",
    "        ]]\n",
    "\n",
    "        # end station data\n",
    "        df_end = df[[\n",
    "            \"endstationid\",\n",
    "            \"endstationname\",\n",
    "            \"endstationlatitude\",\n",
    "            \"endstationlongitude\"\n",
    "        ]]\n",
    "\n",
    "        # rename columns\n",
    "        df_stt.columns = df_stt.columns.str.replace(\"start\", \"\")\n",
    "        df_end.columns = df_end.columns.str.replace(\"end\", \"\")\n",
    "\n",
    "        # get unique station data\n",
    "        df = pd.concat([df_stt, df_end])\n",
    "        df = df.drop_duplicates(subset=[\"stationid\"])\n",
    "\n",
    "        df_station_list.append(df.copy())\n",
    "\n",
    "    # extract full station data\n",
    "    station_data = pd.concat(df_station_list)\n",
    "    station_data = station_data.drop_duplicates(subset=[\"stationid\"])\n",
    "    station_data = station_data.dropna(how=\"any\")\n",
    "    station_data = station_data.sort_values(\"stationname\")\n",
    "    station_data = station_data.reset_index(drop=True)  # remove unused index\n",
    "    station_data = station_data.reset_index(drop=True)  # remove unused index\n",
    "    station_data = station_data.reset_index()  # save unique id from zero\n",
    "    station_data = station_data.astype({\"stationid\": int})\n",
    "\n",
    "    if outpath is not None:\n",
    "        station_data.to_csv(\n",
    "            os.path.join(outpath, \"station_data.csv\"),\n",
    "            index=False)\n",
    "\n",
    "    return station_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# station_data = generate_station_data(start=\"2017-01\", end=\"2020-12\", outpath=OUTPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# station_data.reset_index(drop=True).reset_index()\n",
    "# station_data.stationid.sort_values().reset_index(drop=True).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    \"\"\" Load $ preprocess the original trip data \"\"\"\n",
    "    # Cleaning\n",
    "    df = df.dropna(how=\"any\")\n",
    "    df.columns = df.columns.str.replace(\" \", \"\")\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df = df.query(\"usertype=='Subscriber'\")\n",
    "    df[\"userage\"] = 2013 - df[\"birthyear\"]\n",
    "    df = df[[\"starttime\", \"startstationid\", \"endstationid\", \"userage\"]]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # Cast\n",
    "    df = df.astype({\n",
    "        \"startstationid\": int,\n",
    "        \"endstationid\": int,\n",
    "        \"userage\": int\n",
    "    })\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(start=\"2017-01\", end=\"2020-12\"):\n",
    "\n",
    "    dataset_path = OUTPATH + \"citibike_{}_{}/\".format(\n",
    "        start.replace(\"-\", \"\"), end.replace(\"-\", \"\"))\n",
    "    if os.path.exists(dataset_path):\n",
    "        shutil.rmtree(dataset_path)\n",
    "    os.makedirs(dataset_path)\n",
    "\n",
    "    # Get Station Information\n",
    "    station_data = generate_station_data(start, end, dataset_path)\n",
    "\n",
    "    # Make Monthly Trip History\n",
    "    for date_index in pd.date_range(start=start, end=end, freq='m'):\n",
    "        # print(date_index)\n",
    "\n",
    "        # data processing\n",
    "        df = load_data(date_index.strftime(\"%Y%m\"))\n",
    "        df = process(df)\n",
    "\n",
    "        # encode start station indices\n",
    "        df = pd.merge(df, station_data[[\"index\", \"stationid\"]],\n",
    "                      how=\"left\",\n",
    "                      left_on=\"startstationid\",\n",
    "                      right_on=\"stationid\")\n",
    "\n",
    "        df = df.rename({\"index\": \"start_station_dim\"}, axis=1)\n",
    "        del df[\"stationid\"]\n",
    "\n",
    "        # encode end station indices\n",
    "        df = pd.merge(df, station_data[[\"index\", \"stationid\"]],\n",
    "                      how=\"left\",\n",
    "                      left_on=\"endstationid\",\n",
    "                      right_on=\"stationid\")\n",
    "\n",
    "        df = df.rename({\"index\": \"end_station_dim\"}, axis=1)\n",
    "        del df[\"stationid\"]\n",
    "\n",
    "        # cleaning\n",
    "        df = df.dropna(how=\"any\")\n",
    "\n",
    "        # save\n",
    "        # print(df.head())\n",
    "        filename = \"tripdata_{}.csv\".format(date_index.strftime(\"%Y%m\"))\n",
    "        print(\"[SAVED]\", filename)\n",
    "        df.to_csv(dataset_path + filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 59/59 [02:39<00:00,  2.71s/it]\n",
      "[SAVED] tripdata_201903.csv\n",
      "[SAVED] tripdata_201904.csv\n",
      "[SAVED] tripdata_201905.csv\n",
      "[SAVED] tripdata_201906.csv\n",
      "[SAVED] tripdata_201907.csv\n",
      "[SAVED] tripdata_201908.csv\n",
      "[SAVED] tripdata_201909.csv\n",
      "[SAVED] tripdata_201910.csv\n",
      "[SAVED] tripdata_201911.csv\n",
      "[SAVED] tripdata_201912.csv\n",
      "[SAVED] tripdata_202001.csv\n",
      "[SAVED] tripdata_202002.csv\n",
      "[SAVED] tripdata_202003.csv\n",
      "[SAVED] tripdata_202004.csv\n",
      "[SAVED] tripdata_202005.csv\n",
      "[SAVED] tripdata_202006.csv\n",
      "[SAVED] tripdata_202007.csv\n",
      "[SAVED] tripdata_202008.csv\n",
      "[SAVED] tripdata_202009.csv\n",
      "[SAVED] tripdata_202010.csv\n",
      "[SAVED] tripdata_202011.csv\n",
      "[SAVED] tripdata_202012.csv\n",
      "[SAVED] tripdata_202101.csv\n",
      "[SAVED] tripdata_202102.csv\n",
      "[SAVED] tripdata_202103.csv\n"
     ]
    }
   ],
   "source": [
    "save_dataset(start=\"2019-03\", end=\"2021-04\")  # 2021-04 will be excluded\n",
    "# save_dataset(start=\"2017-01\", end=\"2021-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}